{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the problem is to predict whether a passenger was delighted considering his/her overall travel experience of traveling in Shinkansen (Bullet Train).\n",
    "\n",
    "### Problem Description\n",
    "This is the problem of a Shinkansen (Bullet-Trains) of Japan. They aim to determine the relative importance of each parameter with regards to their contribution to the passenger travel experience. Provided is a random sample of individuals who travelled using their train. The on-time performance of the trains along with the passenger’s information is published in the CSV file named ‘Traveldata_train’. These passengers were later asked to provide their feedback on various parameters related to the travel along with their overall experience. These collected details are made available in the survey report CSV labelled ‘Surveydata_train’.\n",
    "\n",
    "In the survey, a passenger was explicitly asked whether they were delighted with their overall travel experience and that is captured in the data of the survey report under the variable labelled ‘Overall_Experience’.\n",
    "\n",
    "The objective of this exercise is to understand which parameters play an important role in swaying passenger feedback towards a positive scale. You are provided test data containing Travel data and Survey data of passengers. Both the test data and the train data are collected at the same time and belongs to the same company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "# from warnings import filterwarnings \n",
    "# filterwarnings(\"ignore\")\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Machine learning libraries\n",
    "\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix,roc_curve, roc_auc_score,accuracy_score\n",
    "#Import required libraries\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "import ppscore as pps\n",
    "import statistics\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, roc_auc_score, roc_curve, make_scorer, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Traveldata_train.csv')\n",
    "train_survey_data = pd.read_csv('Surveydata_train.csv')\n",
    "test_data = pd.read_csv('Traveldata_test.csv')\n",
    "test_survey_data = pd.read_csv('Surveydata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_data, train_survey_data, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_data, test_survey_data, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = test_df['ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_eda(df):\n",
    "    print('SHAPE')\n",
    "    print(df.shape)\n",
    "    print('.' * 100)\n",
    "    print('\\nINFO')\n",
    "    print(df.info())\n",
    "    print('.' * 100)\n",
    "    print('\\nMISSING VALUES')\n",
    "    print('Total Missing:', df.isna().sum().sum())\n",
    "    print(df.isna().sum())\n",
    "    print('.' * 100)\n",
    "    print('\\nDUPLICATES')\n",
    "    print(df.duplicated().sum())\n",
    "    print('.' * 100)  \n",
    "    print('\\nDESCRIBE')\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_eda(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_eda(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unncessary column\n",
    "\n",
    "train_df.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.dropna(axis = 0, subset = ['Online_boarding', 'Cleanliness', 'Onboard_entertainment', 'Onboardwifi_service',\n",
    "#                                    'Platform_location', 'Age', 'DepartureDelay_in_Mins', 'Seat_comfort', 'Onlinebooking_Ease',\n",
    "#                                    'Checkin_service', 'Gender', 'Leg_room', 'Online_support'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique values in the dataset:\\n')\n",
    "\n",
    "for i in train_df.columns:\n",
    "    print('_' * 50)\n",
    "    print(i.upper() + ':', train_df[i].nunique(), train_df[i].dtype)\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the extremely few records in features and clubbing them with the next best level  \n",
    "\n",
    "train_df['Platform_location'].replace('very inconvinient', 'Inconvinient', inplace = True)\n",
    "train_df['Onboardwifi_service'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Online_support'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Onlinebooking_Ease'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Onboard_service'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Checkin_service'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Cleanliness'].replace('extremely poor', 'poor', inplace = True)\n",
    "train_df['Online_boarding'].replace('extremely poor', 'poor', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating numerical and categorical train data\n",
    "\n",
    "num_train_df = train_df.select_dtypes(exclude = 'object')\n",
    "cat_train_df = train_df.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating numerical and categorical test data\n",
    "\n",
    "num_test_df = test_df.select_dtypes(exclude = 'object')\n",
    "cat_test_df = test_df.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (16, 20), nrows = 4, ncols = 1)\n",
    "\n",
    "for i, col in enumerate(num_train_df.columns[0:4]):\n",
    "    sns.distplot(num_train_df[col], ax = axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.suptitle('Distribution Plot for Numeric Data', y = 1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (16, 8), nrows = 4, ncols = 1)\n",
    "\n",
    "for i, col in enumerate(num_train_df.columns[0:4]):\n",
    "    sns.boxplot(num_train_df[col], ax = axes[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['DepartureDelay_in_Mins'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (16, 8), nrows = 4, ncols = 1)\n",
    "\n",
    "for i, col in enumerate(num_test_df.columns[0:4]):\n",
    "    sns.boxplot(num_test_df[col], ax = axes[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier analysis\n",
    "\n",
    "Q1 = num_train_df.quantile(0.25)\n",
    "Q3 = num_train_df.quantile(0.75) \n",
    "IQR = Q3 - Q1 \n",
    "lower_range = (Q1 - 1.5 * IQR)\n",
    "upper_range = (Q3 + 1.5 * IQR)\n",
    "extreme_lower_range = (Q1 - 3 * IQR)\n",
    "extreme_upper_range = (Q1 + 3 * IQR)\n",
    "\n",
    "pd.DataFrame(((num_train_df < lower_range) | (num_train_df > upper_range)).sum(), \n",
    "             columns = ['No. of Outliers']).sort_values(by = 'No. of Outliers', ascending = False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "sns.heatmap(train_df.corr(), annot = True, annot_kws = {'size': 12}, cmap = 'GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data imputation - median for numeric and mode for categorical\n",
    "\n",
    "for i in num_train_df:\n",
    "    train_df[i].fillna(train_df[i].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_train_df:\n",
    "    train_df[i].fillna(train_df[i].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_df.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Baggage_handling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace = train_df[['Checkin_service', 'Leg_room', 'Onboard_service', 'Onlinebooking_Ease', 'Online_support',\n",
    "#             'Onboardwifi_service', 'Cleanliness', 'Platform_location', 'Catering', 'Arrival_time_convenient',\n",
    "#             'Seat_comfort', 'Onboard_entertainment', 'Online_boarding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual categorical data encoding\n",
    "\n",
    "train_df['Checkin_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Leg_room'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Onboard_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Onlinebooking_Ease'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Online_support'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Onboardwifi_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Cleanliness'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Platform_location'].replace(['very inconvinient', 'Inconvinient', 'need improvement', 'manageable', 'Convinient', 'very convinient'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Catering'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Arrival_time_convenient'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Seat_comfort'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Onboard_entertainment'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "train_df['Online_boarding'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "\n",
    "train_df['Baggage_handling'].replace(['poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4], inplace = True)\n",
    "\n",
    "train_df['Seat_Class'].replace(['Green Car', 'Ordinary'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "train_df['Travel_Class'].replace(['Eco', 'Business'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "train_df['TypeTravel'].replace(['Business travel', 'Personal Travel'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "train_df['CustomerType'].replace(['Loyal Customer', 'disloyal Customer'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "train_df['Gender'].replace(['Female', 'Male'], [1, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check predictive power score\n",
    "\n",
    "pps.predictors(train_df, \"Overall_Experience\")[['x', 'y', 'ppscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables with high predictive power score\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "predictors_df = pps.predictors(train_df, \"Overall_Experience\")\n",
    "sns.barplot(data = predictors_df.nlargest(11, 'ppscore'), x= \"x\", y = \"ppscore\")\n",
    "print(plt.xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables with low predictive power score\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "predictors_df = pps.predictors(train_df, \"Overall_Experience\")\n",
    "sns.barplot(data = predictors_df.nsmallest(15, 'ppscore'), x= \"x\", y = \"ppscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df.nsmallest(12, 'ppscore').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['DepartureDelay_in_Mins'] = np.where(train_df['DepartureDelay_in_Mins'] > 1000, train_df['DepartureDelay_in_Mins'].median(), train_df['DepartureDelay_in_Mins'])\n",
    "# train_df['ArrivalDelay_in_Mins'] = np.where(train_df['ArrivalDelay_in_Mins'] > 1000, train_df['DepartureDelay_in_Mins'].median(), train_df['ArrivalDelay_in_Mins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['Online_Score'] = train_df['Online_support'] + train_df['Onlinebooking_Ease'] + train_df['Online_boarding']\n",
    "# train_df['Prior_boarding'] = train_df['Baggage_handling'] + train_df['Catering'] + train_df['Checkin_service']+ train_df['Platform_location']\n",
    "# train_df['Onboard_Score'] = train_df['Onboard_entertainment'] + train_df['Onboard_service'] + train_df['Onboardwifi_service']\n",
    "# train_df['Comfort_Score'] = train_df['Cleanliness'] + train_df['Leg_room'] + train_df['Seat_comfort']\n",
    "# train_df['Covered'] = train_df['DepartureDelay_in_Mins'] - train_df['ArrivalDelay_in_Mins']\n",
    "\n",
    "train_df['Dep_Delay_HRS'] = train_df['DepartureDelay_in_Mins'] / 60\n",
    "train_df['Arr_Delay_HRS'] = train_df['ArrivalDelay_in_Mins'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "\n",
    "plt.figure(figsize = (24, 24))\n",
    "sns.heatmap(train_df.corr(), annot = True, square = True, annot_kws = {'size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(train_df.corr()['Overall_Experience']).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking same preprocessing steps as training data \n",
    "\n",
    "for i in num_test_df:\n",
    "    test_df[i].fillna(test_df[i].median(), inplace = True)\n",
    "\n",
    "for i in cat_test_df:\n",
    "    test_df[i].fillna(test_df[i].mode()[0], inplace = True)\n",
    "\n",
    "test_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Onboardwifi_service'].replace('extremely poor', 'poor', inplace = True)\n",
    "test_df['Onlinebooking_Ease'].replace('extremely poor', 'poor', inplace = True)\n",
    "test_df['Online_boarding'].replace('extremely poor', 'poor', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Checkin_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Leg_room'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Onboard_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Onlinebooking_Ease'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Online_support'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Onboardwifi_service'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Cleanliness'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Platform_location'].replace(['very inconvinient', 'Inconvinient', 'need improvement', 'manageable', 'Convinient', 'very convinient'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Catering'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Arrival_time_convenient'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Seat_comfort'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Onboard_entertainment'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "test_df['Online_boarding'].replace(['extremely poor', 'poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "\n",
    "test_df['Baggage_handling'].replace(['poor', 'need improvement', 'acceptable', 'good', 'excellent'], \n",
    "                                    [0, 1, 2, 3, 4], inplace = True)\n",
    "\n",
    "test_df['Seat_Class'].replace(['Green Car', 'Ordinary'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "test_df['Travel_Class'].replace(['Eco', 'Business'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "test_df['TypeTravel'].replace(['Business travel', 'Personal Travel'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "test_df['CustomerType'].replace(['Loyal Customer', 'disloyal Customer'], \n",
    "                                    [0, 1], inplace = True)\n",
    "\n",
    "test_df['Gender'].replace(['Female', 'Male'], [1, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['DepartureDelay_in_Mins'] = np.where(test_df['DepartureDelay_in_Mins'] > 1000, test_df['DepartureDelay_in_Mins'].median(), test_df['DepartureDelay_in_Mins'])\n",
    "# test_df['ArrivalDelay_in_Mins'] = np.where(test_df['ArrivalDelay_in_Mins'] > 1000, test_df['DepartureDelay_in_Mins'].median(), test_df['ArrivalDelay_in_Mins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['Online_Score'] = test_df['Online_support'] + test_df['Onlinebooking_Ease'] + test_df['Online_boarding']\n",
    "# test_df['Prior_boarding'] = test_df['Baggage_handling'] + test_df['Catering'] + test_df['Checkin_service']+ test_df['Platform_location']\n",
    "# test_df['Onboard_Score'] = test_df['Onboard_entertainment'] + test_df['Onboard_service'] + test_df['Onboardwifi_service']\n",
    "# test_df['Comfort_Score'] = test_df['Cleanliness'] + test_df['Leg_room'] + test_df['Seat_comfort']\n",
    "# test_df['Covered'] = test_df['DepartureDelay_in_Mins'] - test_df['ArrivalDelay_in_Mins']\n",
    "\n",
    "test_df['Dep_Delay_HRS'] = test_df['DepartureDelay_in_Mins'] / 60\n",
    "test_df['Arr_Delay_HRS'] = test_df['ArrivalDelay_in_Mins'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(['ID', 'Seat_Class'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['Overall_Experience', 'Seat_Class'], axis = 1)\n",
    "\n",
    "y = train_df['Overall_Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "# X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAX VOTING ENSEMBLE - [TEST ACC: 0.9580922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: some below provided hyperparameters might have been altered and is not the set that gave the best test score\n",
    "# Train accuracy score of 0.9886376934943348 gave the best test score of .9580922 \n",
    "\n",
    "\n",
    "model1 = CatBoostClassifier(random_state = 1, verbose = False,\n",
    "                              iterations = 1000,\n",
    "                              depth = 6,\n",
    "                              random_strength = 1e-5)\n",
    "\n",
    "model2 = lgb.LGBMClassifier(random_state = 1,\n",
    "                              boosting_type = 'gbdt',\n",
    "                              num_leaves = 31,  \n",
    "                              max_depth = 12,  \n",
    "                              n_estimators = 950,  \n",
    "                              learning_rate = 0.1,\n",
    "                              colsample_bytree = 0.6,\n",
    "                              n_jobs = 4)\n",
    "\n",
    "model3 = XGBClassifier(random_state = 1, \n",
    "                         n_jobs = 4,\n",
    "                         n_estimators = 800,\n",
    "                         max_depth = 15,   \n",
    "                         colsample_bylevel = 0.7,\n",
    "                         learning_rate = 0.0891)\n",
    "\n",
    "\n",
    "\n",
    "model1.fit(X, y)\n",
    "model2.fit(X, y)\n",
    "model3.fit(X, y)\n",
    "\n",
    "\n",
    "pred1 = model1.predict(test_df)\n",
    "pred2 = model2.predict(test_df)\n",
    "pred3 = model3.predict(test_df)\n",
    "\n",
    "\n",
    "# final test predictions\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(test_df)):\n",
    "    final_pred = np.append(final_pred, statistics.mode([pred1[i], pred2[i], pred3[i]]))\n",
    "    \n",
    "\n",
    "# scoring on train data   \n",
    "preda = model1.predict(X)\n",
    "predb = model2.predict(X)\n",
    "predc = model3.predict(X)\n",
    "\n",
    "check_pred = np.array([])\n",
    "for i in range(0,len(X)):\n",
    "    check_pred = np.append(check_pred, statistics.mode([preda[i], predb[i], predc[i]]))\n",
    "    \n",
    "\n",
    "accuracy_score(y, check_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "\n",
    "pd.DataFrame(model3.feature_importances_, index = X.columns, columns = ['Feature Imp']).sort_values('Feature Imp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y, check_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall_Experience = pd.DataFrame(final_pred, columns = ['Overall_Experience'])\n",
    "submission117 = pd.concat([ID, Overall_Experience], axis = 1)\n",
    "submission117.to_csv('submission00117.csv', index = False)\n",
    "sub117 = pd.read_csv('submission00117.csv')\n",
    "sub117.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
